
# ğŸ™ï¸ Voice-Operated Agentic Coding Assistant

**Stateful, Tool-Using AI with LangGraph & Persistent Memory**

A **voice-controlled, agentic coding assistant** built using **Python and LangGraph**, capable of **planning, reasoning, and executing multi-step file and command-line operations** while persisting state across sessions.

The system combines **LLM-driven decision making**, **tool execution**, and **durable task memory** using **MongoDB**, enabling long-running, resumable coding workflows.

---

## ğŸš€ Key Capabilities

### âœ… Implemented Features

* **Voice-Driven Interaction**

  * Real-time speech-to-text using `SpeechRecognition`
  * Hands-free coding and system control

* **Agentic Workflow via LangGraph**

  * Explicit state machine with conditional transitions
  * Separation of reasoning and tool execution
  * Deterministic control over agent behavior

* **Tool-Using Coding Agent**

  * Executes system commands via registered tools
  * Designed for file creation, project setup, and shell operations
  * Enforced workspace isolation (`chat_gpt/` directory)

* **Stateful Conversations**

  * Conversation history persisted using **MongoDB**
  * Supports resumable sessions across restarts
  * Checkpointed graph execution using `MongoDBSaver`

* **Gemini-Powered Reasoning**

  * Google Gemini used for planning and response generation
  * Tool decisions inferred from natural language input

* **Containerized Infrastructure**

  * MongoDB deployed via Docker Compose
  * Environment-agnostic local setup

---

## ğŸ§  System Architecture

```
Voice Input (Microphone)
        â”‚
Speech Recognition
        â”‚
LangGraph State Machine
        â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Chatbot   â”‚  â†â”€ Gemini Reasoning
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚ (conditional)
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
 â”‚ Tool Node   â”‚  â†â”€ Command Execution
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
MongoDB Checkpointing
        â”‚
 Persistent Agent State
```

---

## ğŸ› ï¸ Tech Stack

| Layer             | Technology             |
| ----------------- | ---------------------- |
| Language          | Python                 |
| Agent Framework   | LangGraph              |
| LLM               | Google Gemini          |
| Speech            | SpeechRecognition      |
| State Persistence | MongoDB                |
| Tool Execution    | LangChain Tools        |
| Containerization  | Docker, Docker Compose |

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ graph.py                 # LangGraph agent definition
â”œâ”€â”€ main.py                  # Voice interaction + runtime loop
â”œâ”€â”€ docker-compose.yml       # MongoDB container
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ chat_gpt/                # Agent-created workspace
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/voice-agentic-coding-assistant.git
cd voice-agentic-coding-assistant
```

### 2ï¸âƒ£ Environment Setup

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure Environment Variables

Create a `.env` file:

```env
GOOGLE_API_KEY=your_gemini_api_key
```

### 4ï¸âƒ£ Start MongoDB

```bash
docker-compose up -d
```

### 5ï¸âƒ£ Run the Assistant

```bash
python main.py
```

---

## ğŸ§ Example Usage

```
User (voice):
"Create a Python file that prints system information"

Assistant:
â†’ Plans task
â†’ Executes shell commands
â†’ Creates files inside chat_gpt/
â†’ Responds with execution result
```

The agent:

* Decides **when to use tools**
* Executes commands safely
* Persists state for future continuation

---

## ğŸ§ª Current Limitations (Transparent)

* Text-to-Speech output not yet integrated
* Tooling currently limited to shell execution
* No permission sandboxing (local-only usage recommended)
* Qdrant-based codebase RAG planned but not yet wired

---

## ğŸ›£ï¸ Roadmap

### ğŸ”œ Planned Enhancements

* Codebase-aware RAG using **Qdrant**
* Secure sandboxed command execution
* Text-to-Speech output
* Multi-agent task delegation
* IDE integration (VS Code / CLI plugin)

---

## ğŸ“Œ Why This Project Is Important

This project demonstrates:

* **True agentic design** (not prompt chaining)
* **State machines for LLM control**
* **Persistent AI systems**
* **Tool-calling with real execution**
* **Voice-first developer interfaces**

It reflects **production-oriented agent engineering**, not demos.

---
